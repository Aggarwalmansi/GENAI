{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text = \"Umg ... The deliveries were DELAYED! I seriously hate waiting... #annoyed\"\n",
    "# Lowercase\n",
    "text_lower = text.lower()\n",
    "\n",
    "# remove Punctuation using string translation\n",
    "# this ceates a table that swaps punctuation for 'Nothing'\n",
    "\n",
    "translator = str.maketrans('','',string.punctuation)\n",
    "clean_text = text_lower.translate(translator)\n",
    "\n",
    "print(\"Original:\",text)\n",
    "print(\"Cleaned:\",clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simple way (split by space)\n",
    "tokens = clean_text.split()\n",
    "print(\"Tokens:\",tokens)\n",
    "print(\"Token Count:\",len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "from transformers import AutoTokenizer\n",
    "# We will use the BERT tokenizer (Standard in industry)\n",
    "# This requirs internet to download the vocab\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "complex_text = \"The microtransactional system was counterintuitive\"\n",
    "print(\"Token\",tokenizer.tokenize(complex_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "print(tokenizer.tokenize(\"मुझे हिंदी पढ़ना अच्छा लगता है।\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize\n",
    "text = \"मुझे हिंदी पढ़ना अच्छा लगता है।\"\n",
    "token = indic_tokenize.trivial_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"सत्यं ब्रूयात् प्रियं ब्रूयात्\"\n",
    "token = indic_tokenize.trivial_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_tokens = [word for word in token if word not in stop_words]\n",
    "print(\"InputL\",token)\n",
    "print(\"Output:\",filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer , WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [\"deliveries\",\"waiting\",\"delayed\",\"studies\"]\n",
    "for w in words :\n",
    "  print(w,\"|\",stemmer.stem(w),\"|\",lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "words = ['car','automobile']\n",
    "embeddings = model.encode(words)\n",
    "for i in range(2):\n",
    "  print(\"Word:\",words[i],\"Embedding:\",embeddings[i][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking similarity using cos sin similarity\n",
    "from sentence_transformers import util\n",
    "util.cos_sim(embeddings[0],embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"/content/drive/MyDrive/Colab Notebooks\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/Colab Notebooks/NLP.ipynb\" /content/\n",
    "!ls /content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "NOTEBOOK = \"/content/NLP.ipynb\"  # exact name\n",
    "\n",
    "nb = nbformat.read(NOTEBOOK, as_version=4)\n",
    "nb.metadata.pop(\"widgets\", None)\n",
    "nbformat.write(nb, NOTEBOOK)\n",
    "\n",
    "print(\"✅ widget metadata removed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "NOTEBOOK = \"/content/NLP.ipynb\"  # <-- change if needed\n",
    "\n",
    "nb = nbformat.read(NOTEBOOK, as_version=4)\n",
    "\n",
    "# 1. Remove notebook-level widget metadata\n",
    "nb.metadata.pop(\"widgets\", None)\n",
    "\n",
    "# 2. Remove widget metadata from every cell\n",
    "for cell in nb.cells:\n",
    "    cell.metadata.pop(\"widgets\", None)\n",
    "    cell.metadata.pop(\"widget\", None)\n",
    "\n",
    "    # 3. Clean widget-related outputs\n",
    "    if \"outputs\" in cell:\n",
    "        cleaned_outputs = []\n",
    "        for output in cell.outputs:\n",
    "            if output.get(\"output_type\") == \"display_data\":\n",
    "                data = output.get(\"data\", {})\n",
    "                if \"application/vnd.jupyter.widget-view+json\" in data:\n",
    "                    continue  # DROP widget output entirely\n",
    "            cleaned_outputs.append(output)\n",
    "        cell.outputs = cleaned_outputs\n",
    "\n",
    "nbformat.write(nb, NOTEBOOK)\n",
    "\n",
    "print(\"✅ ALL widget metadata and outputs removed. GitHub-safe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert /content/NLP.ipynb \\\n",
    "  --to notebook \\\n",
    "  --ClearOutputPreprocessor.enabled=True \\\n",
    "  --ClearMetadataPreprocessor.enabled=True \\\n",
    "  --output NLP_clean.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/NLP_clean.ipynb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Aggarwalmansi/GENAI.git"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
